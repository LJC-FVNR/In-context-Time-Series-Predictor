{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9bf36-213f-4741-a6c2-ce606a616dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotly\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from data_provider.data_factory import data_provider_subset as data_provider\n",
    "from data_provider.ictsp_dataloader import ForecastingDatasetWrapper\n",
    "from types import SimpleNamespace\n",
    "from models.ICPretrain import ICPretrain\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import json\n",
    "with open('configs/pretrain_configs_sequential.json', 'r') as file:\n",
    "    config_data = json.load(file)\n",
    "icpretrain_configs = SimpleNamespace(**config_data)\n",
    "icpretrain_configs.stage = \"inference\"\n",
    "weight_path = './pt_model_2048_96_current.pth'\n",
    "model_name = 'ICTSP_FT'\n",
    "\n",
    "def nested_collate_fn(batch):\n",
    "    elem = batch[0]\n",
    "    elem_type = type(elem)\n",
    "    \n",
    "    if isinstance(elem, np.ndarray):\n",
    "        tensor_batch = list(map(torch.Tensor, batch))\n",
    "        return torch.nested.nested_tensor(tensor_batch)\n",
    "    elif isinstance(elem, float):\n",
    "        return torch.tensor(batch, dtype=torch.float)\n",
    "    elif isinstance(elem, int):\n",
    "        return torch.LongTensor(batch)\n",
    "    elif isinstance(elem, str):\n",
    "        return batch\n",
    "    elif isinstance(elem, tuple):\n",
    "        transposed = zip(*batch)\n",
    "        return [nested_collate_fn(samples) for samples in transposed]\n",
    "    elif isinstance(elem, list):\n",
    "        transposed = zip(*batch)\n",
    "        return [nested_collate_fn(samples) for samples in transposed]\n",
    "    else:\n",
    "        print(batch)\n",
    "        raise TypeError(f\"batch must contain tensors, numpy arrays or numbers; found {elem_type}\")\n",
    "\n",
    "def get_dataset(seq_len=2048, pred_len=720, data_type='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', train_ratio=0.7, test_ratio=0.2, \n",
    "                flag='test', do_forecasting=False, batch_size=8, force_lookback=52):\n",
    "    data_args = SimpleNamespace(embed='timeF', \n",
    "                                batch_size=batch_size,\n",
    "                                batch_size_test=batch_size,\n",
    "                                freq='h',\n",
    "                                data=data_type,\n",
    "                                root_path=root_path,\n",
    "                                data_path=data_path,\n",
    "                                seq_len=seq_len,\n",
    "                                label_len=0,\n",
    "                                pred_len=pred_len,\n",
    "                                features='M',\n",
    "                                target='OT',\n",
    "                                scale=1,\n",
    "                                train_ratio=train_ratio,\n",
    "                                test_ratio=test_ratio,\n",
    "                                num_workers=0,\n",
    "                                do_forecasting=do_forecasting\n",
    "                                )\n",
    "    dataset, dataloader = data_provider(data_args, flag=flag)\n",
    "    ds = ForecastingDatasetWrapper(dataset, icpretrain_configs)\n",
    "    ds.force_legacy_lookback_for_inference = force_lookback\n",
    "    dl = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=False,\n",
    "        collate_fn=nested_collate_fn)\n",
    "    return ds, dl\n",
    "\n",
    "def preprocess_data(data, device):\n",
    "    # flipped both in the tokenizer and the preprocessing here, just to ensure the \"float to the right\" alignment format properly applied on the channel dimension\n",
    "    task_id = data[8].int().to(device, non_blocking=True)\n",
    "    token_x_part = torch.nested.to_padded_tensor(data[0].float().to(device, non_blocking=True), 0).flip(1)\n",
    "    y_true = torch.nested.to_padded_tensor(data[1].float().to(device, non_blocking=True), 0).flip(1) if task_id[0] != 1 else torch.nested.to_padded_tensor(data[1].int().to(device, non_blocking=True), 0).flip(1)      # C L or C\n",
    "    token_y_part = torch.nested.to_padded_tensor(data[2].float().to(device, non_blocking=True), 0).flip(1) if task_id[0] != 1 else torch.nested.to_padded_tensor(data[2].int().to(device, non_blocking=True), 0).flip(1)\n",
    "    channel_label = torch.nested.to_padded_tensor(data[3].int().to(device, non_blocking=True), 0).flip(1)\n",
    "    position_label = torch.nested.to_padded_tensor(data[4].int().to(device, non_blocking=True), 0).flip(1)\n",
    "    source_label = torch.nested.to_padded_tensor(data[5].int().to(device, non_blocking=True), 0).flip(1)\n",
    "    tag_multihot = torch.nested.to_padded_tensor(data[6].float().to(device, non_blocking=True), 0).flip(1)\n",
    "    y_true_shape = torch.nested.to_padded_tensor(data[7].int().to(device, non_blocking=True), 0)\n",
    "    return task_id, token_x_part, y_true, token_y_part, channel_label, position_label, source_label, tag_multihot, y_true_shape\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = ICPretrain(icpretrain_configs)#.float()\n",
    "\n",
    "#weight_path = './pt_model_2048_96_current.pth'\n",
    "\n",
    "state_dict = torch.load(weight_path, map_location='cpu')\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] if k.startswith('module.') else k  # remove `module.` prefix\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "model.load_state_dict(new_state_dict) #, strict=False\n",
    "\n",
    "for attribute in dir(model):\n",
    "    if isinstance(getattr(model, attribute), torch._dynamo.eval_frame.OptimizedModule):\n",
    "        setattr(model, attribute, getattr(model, attribute)._orig_mod)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model.process_output = True\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c33a788-14f7-40d4-9348-32b6a6f14230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your inference data\n",
    "data_path = 'main.csv'\n",
    "\n",
    "# seq_len: L_I, force_lookback: L_b, pred_len: L_P\n",
    "vali_data, vali_loader = get_dataset(seq_len=416, pred_len=4, data_type='custom', root_path='./dataset/', data_path=data_path, train_ratio=0.87, test_ratio=0.1, \n",
    "                                  flag='val', do_forecasting=True, batch_size=8, force_lookback=104)\n",
    "test_data, test_loader = get_dataset(seq_len=416, pred_len=4, data_type='custom', root_path='./dataset/', data_path=data_path, train_ratio=0.87, test_ratio=0.1, \n",
    "                                  flag='test', do_forecasting=True, batch_size=8, force_lookback=104)\n",
    "number_of_targets = 0  # All\n",
    "\n",
    "def calculation(dataloader):\n",
    "    preds = []\n",
    "    trues = []\n",
    "    number_of_targets = 53\n",
    "    index = 0\n",
    "    # x: (L_I, C), y: (L_P, C)\n",
    "    for index, data in tqdm(enumerate(dataloader)):\n",
    "        task_id, token_x_part, y_true, token_y_part, channel_label, position_label, source_label, tag_multihot, y_true_shape = preprocess_data(data, device=device)\n",
    "        with torch.no_grad():\n",
    "            res = model(token_x_part, token_y_part, channel_label, position_label, source_label, tag_multihot, y_true_shape, task_id)\n",
    "            res = res.detach().cpu().numpy().transpose((0, 2, 1))[:, :, -number_of_targets:]\n",
    "            y = y_true.detach().cpu().numpy().transpose((0, 2, 1))[:, :, -number_of_targets:]\n",
    "        preds.append(res)\n",
    "        trues.append(y)\n",
    "        index += 1\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    trues = np.concatenate(trues, axis=0)\n",
    "    return preds, trues\n",
    "\n",
    "preds_vali, trues_vali = calculation(vali_loader)\n",
    "preds, trues = calculation(test_loader)\n",
    "preds.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
